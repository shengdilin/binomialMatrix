%! TEX root = thesis.tex
\chapter{Sampling Datasets}

\section{Existing Method}\label{sec:gionis}

\Citet{GionisMMT07} introduce an algorithm (which we refer to as \gioalgo) for
sampling \emph{uniformly} at random from a set $\matrices$ of \emph{binary
matrices}. For ease of presentation in this subsection, we limit ourselves to the
uniform distribution over $\matrices$, but all that we say here can be extended
to a generic distribution over $\matrices$. The basis for presenting \gioalgo\ as
an algorithm for sampling \emph{datasets} from a SLISP null model $\nullmodel =
(\nullset, \uniform{\nullset})$ for an observed dataset $\odataset$ is the
\emph{unstated assumption} that there is \emph{always} a \emph{bijection}
between $\nullset$ and the set $\matrices$ of binary matrices from which
\gioalgo\ samples. We show (\cref{lem:wrongsampling}) that \emph{the assumption
is false}, and \gioalgo\ samples datasets from a ``distorted'' null model with a
probability distribution that is not necessarily uniform.

\subsection{Datasets as Matrices}

We first must give some more detail about \gioalgo. This algorithm implicitly
assumes that datasets, rather than being \emph{bags} of transactions, are
\emph{sequences}, i.e., the transactions in them have a fixed \emph{order}. We
refer to datasets seen as sequences with the term ``seq-datasets''. Clearly,
since there are many possible orderings of the transactions of a dataset,
multiple seq-datasets may correspond to the same dataset. This assumption allows
to define a bijection that maps any seq-dataset $\dataset = \langle t_1, \dotsc,
t_\rowsnum \rangle$ with $\rowsnum$ transactions built on the alphabet $\items =
  \{1, \dotsc, \colsnum\}$ of items to one and only one binary matrix $
  M_\dataset \in {\{0, 1\}}^{\rowsnum \times \colsnum}$ with $\rowsnum$ rows and
$\colsnum$ columns by setting the entry $M_\dataset(i,j)$ to 1 iff $j \in t_i$,
$1 \le j \le \colsnum$, $1 \le i \le \rowsnum$. For example, assuming $\items =
  \{1, 2, 3\}$, the seq-dataset
\begin{equation}\label{eq:sampledataset}
  \dataset' = \langle \{1, 2\}, \{1, 3\}, \{3\} \rangle
\end{equation}
is mapped to the matrix
\begin{equation}\label{eq:sampledatasetmatrix}
  M_{\dataset'} = \left[
  \begin{array}{ccc}
    1 & 1 & 0 \\
    1 & 0 & 1 \\
    0 & 0 & 1
  \end{array}
  \right] \enspace.
\end{equation}
Given an observed dataset $\odataset$, \gioalgo\ maps it to a seq-dataset
$\odataset'=\langle t_1, \dotsc, t_\rowsnum\rangle$ by arbitrarily choosing an
order for the transactions in $\odataset$. \gioalgo\ then defines the set
$\matrices \subseteq {\{0, 1\}}^{\rowsnum \times \colsnum}$ of all $\rowsnum
\times \colsnum$ binary matrices $M$ such that
\begin{itemize}
  \item for $1 \le i \le \rowsnum$, $\rowsum{i} \doteq \sum_{j=1}^\colsnum M(i,j)
    = \card{t_i}$, i.e., the \emph{row-sum $\rowsum{i}$} (that is, the number of
    $1$'s in row $i$) equals the length of the transaction $t_i$; and
  \item for $1 \le j \le \colsnum$, $\colsum{j} \doteq \sum_{i=1}^\rowsnum M(i,j) =
    \supp{\odataset}{\{j\}}$, i.e., the \emph{column-sum $\colsum{j}$} (that is,
    the number of $1$'s in column $j$) equals the support of item $j$ in
    $\odataset$.
\end{itemize}
The set $\matrices$ depends on both $\odataset$ and the chosen ordering of its
transactions to obtain the seq-dataset $\odataset'$.

Again, suppose for example we observe dataset $\odataset = \{\{1, 2\}, \{1, 3\},
\{3\}\}$. Further suppose that the chosen ordering of the transactions of
$\odataset$ is such that we obtain $\odataset'$ as the seq-dataset $\dataset'$
from~\eqref{eq:sampledataset}. It follows that the matrix representation
$M_{\odataset'}$ of the seq-dataset $\odataset'$ is the matrix $M_{\dataset'}$
from~\eqref{eq:sampledatasetmatrix}. Then, matrices $M$ in the set $\matrices$
of binary matrices include (but are not limited to)
\[
  \left[
  \begin{array}{ccc}
    1 & 1 & 0 \\
    1 & 0 & 1 \\
    0 & 0 & 1
  \end{array}
  \right],\
  \left[
  \begin{array}{ccc}
    1 & 0 & 1 \\
    1 & 1 & 0 \\
    0 & 0 & 1
  \end{array}
  \right],\
  \text{and}\
  \left[
  \begin{array}{ccc}
    1 & 0 & 1 \\
    1 & 0 & 1 \\
    0 & 1 & 0
  \end{array}
  \right],
\]
since each matrix $M$ preserves the row-sums and column-sums of the matrix
$M_{\odataset'}$. Notice that the matrix $M_{\odataset'}$ itself is in the set
$\matrices$ of binary matrices. Also observe that the first two rows of the
first matrix $M_{\odataset'}$ can be reordered to obtain the seconds matrix,
while the rows cannot be reordered to obtain the third matrix but this matrix is
still in $\matrices$. This observation will be important in the proof for
\cref{lem:wrongsampling}.

\subsection{Swap Randomization}

\gioalgo\ samples from $\matrices$ uniformly at random using the MCMC approach
with MH (\cref{sec:prelims:markov}). The state space is $\matrices$ and there is
an edge from matrix $M'$ to matrix $M''$ if there are two row indices $1 \le
r_1, r_2 \le \rowsnum$ and two column indices $1 \le c_1, c_2 \le \colsnum$ such
that $M'(r_1, c_1) = 1$, $M'(r_1, c_2) = 0$, $M'(r_2,c_1) = 0$, $M'(r_2,c_2)=1$,
and $M''$ can be obtained from $M'$ by setting  $M'(r_1, c_1) = 0$, $M'(r_1,
c_2) = 1$, $M'(r_2,c_1) = 1$, and $M'(r_2,c_2)=0$, i.e., by performing a single
\emph{swap}. For example, given a matrix
\[
  M' = \left[
    \begin{array}{ccc}
      1 & 1 & 0 \\
      1 & 0 & 1 \\
      0 & 0 & 1
    \end{array}
    \right]
  \in\ \matrices,
\]
a different matrix
\[
  M'' = \left[
    \begin{array}{ccc}
      1 & 0 & 1 \\
      1 & 0 & 1 \\
      0 & 1 & 0
    \end{array}
    \right]
  \in\ \matrices\
\]
can be obtained by performing a single swap w.r.t.\ to row indices $r_1 = 1, r_2
= 3$ and column indices $c_1 = 2, c_2 = 3$. The distribution $\neighprob_M$ is
the uniform over the out-neighbors of $M \in \matrices$, i.e., $\neighprob_M(M')
\doteq 1 / \totspairsnummat{M}$, where $\totspairsnummat{M}$ of is the number of
out-neighbors of $M$. \citet[Alg.\ 2, Thm.\ 4.3]{GionisMMT07} give procedures to
draw a neighbor according to $\neighprob_M$, and to compute
$\totspairsnummat{M}$, $M \in \matrices$, which are needed by MH\@. We use this
result in our algorithms, so we report it here for self-containedness.

\begin{theorem}[\lbrack\citealp{GionisMMT07}, Thm.\ 4.3\rbrack]\label{thm:totspairsnummat}
  Let $M_{\dataset}$ be a matrix representation of dataset $\dataset$, and let
  $\squaredmat = M_{\dataset} M_{\dataset}^\intercal$. Then
  \begin{equation}\label{eq:totspairsnummat}
    \totspairsnummat{M_{\dataset}} = \dpairsnum{\dataset} -
    \zstructsnum{\dataset} + \kttsnum{M_{\dataset}},
  \end{equation}
  where
  \begin{align*}
    \dpairsnum{\dataset} &\doteq \frac{1}{2} \left( \left( 1 +
    \sum_{t \in \dataset} \card{t} \right) \sum_{t \in \dataset}
    \card{t} - \sum_{t \in \dataset} \card{t}^2 - \sum_{i \in \items}
    {(\supp{\dataset}{\{i\}})}^2 \right),\\
    \zstructsnum{\dataset} &\doteq \sum_{t \in \dataset} \sum_{i \in t} [
    (\card{t} - 1) (\supp{\dataset}{\{i\}} -1) ],\ \text{and}\\
    \kttsnum{M_{\dataset}} &\doteq \sum_{k = 1}^{\rowsnum} \sum_{\ell
    =1}^{k-1} [{(\squaredmat(\ell, k))}^2 - \squaredmat(\ell, k) ] \enspace.
  \end{align*}
\end{theorem}

A run of the chain can be seen as a sequence of swaps, hence the name \emph{swap
randomization} for the approach taken by \gioalgo. Define the surjective
function $\mattodat{\cdot}$ from $\matrices$ to the null set $\nullset$ of the
SLISP null model for $\odataset$, which maps $M \in \matrices$ to the
\emph{unique} dataset obtained by considering as a bag the seq-dataset
mapped to $M$. After a sufficient number of swaps, the state $M$ of the
chain is distributed uniformly \emph{among $\matrices$}, and the dataset
$\mattodat{M}$ is returned as a sample from $\nullset$.

\begin{lemma}\label{lem:wrongsampling}
  There exists an observed dataset $\odataset$ such that, if we let $M$ be a
  matrix drawn uniformly at random from $\matrices$, then $\mattodat{M}$ is not
  chosen uniformly at random from $\nullset$.
\end{lemma}

\begin{proof}
  Let $\odataset = \{ \{1, 2\}, \{1, 3\}, \{3\} \}$, and assume, w.l.o.g., that
  $\odataset'$ is the seq-dataset $\dataset'$ from~\eqref{eq:sampledataset},
  then clearly the matrix $M_{\dataset'}$ from~\eqref{eq:sampledatasetmatrix}
  belongs to $\matrices$.

  The set $\matrices$ also contains the matrix $M''$ obtained by reordering the
  first two rows of $M_{\dataset'}$ from~\eqref{eq:sampledatasetmatrix}, which
  corresponds to the seq-dataset $\dataset'' = \langle \{1, 3\}, \{1, 2\}, \{3\}
  \rangle$. The seq-datasets $\dataset'$ from~\eqref{eq:sampledataset} and
  $\dataset''$ are \emph{different}, but their corresponding datasets
  respectively are \emph{the same dataset}, i.e., $\mattodat{M_{\dataset'}} =
  \mattodat{M''}$. Thus, the set $\matrices$ contains \emph{at least two}
  matrices mapped to seq-datasets that, when seen as bags, are equal to
  $\odataset$. From the definition of $\matrices$, it holds that $\matrices$
  also contains
  \[
    A \doteq \left[
    \begin{array}{ccc}
      1 & 0 & 1 \\
      1 & 0 & 1 \\
      0 & 1 & 0
    \end{array}
    \right] \enspace.
  \]
  It holds that $\mattodat{A} = \{\{1,3\}, \{1, 3\}, \{2\}\}$. Again from the
  definition of $\matrices$, it holds that there is no other matrix $B$
  different than $A$ in $\matrices$ such that $\mattodat{B}= \mattodat{A}$.
  Thus, if we sample a matrix $M$ uniformly at random from $\matrices$ there is
  a higher probability that $\mattodat{M} = \odataset$ than $\mattodat{M} =
  \mattodat{A}$, and our proof is complete.
\end{proof}

\Cref{lem:wrongsampling} says that, if one wants to sample datasets from a SLISP
null model $\nullmodel=(\nullset,\nullprob)$, the samples obtained by using
\gioalgo\ are actually drawn from a \emph{distorted} null model
$\wiggly{\nullmodel}=(\nullset, \wiggly{\nullprob})$, where $\wiggly{\nullprob}
\neq \nullprob$. As discussed in \cref{sec:prelims:significant}, these samples
are intended to be used to compute key quantities ($p$-values and adjusted
critical values) for evaluating the significance of results w.r.t.\
$\nullmodel$, but given that they are not distributed according to $\nullprob$,
any conclusion drawn using these samples could potentially be wrong. In the next
section, we introduce \algo, our suite of algorithms to sample datasets from
SLISP null models \emph{without distortion}.

Before moving on, we mention that the root cause of the distortion is,
informally, the choice to consider the order of the transactions in a dataset as
meaningful for knowledge discovery tasks, when it is not: these tasks are
effectively defined on datasets seen as \emph{unordered} bags of transactions.
Transaction identifiers are irrelevant for most knowledge discovery tasks. E.g.,
no pattern mining algorithm requires such identifiers. Thus, there is no reason
to require the order of transactions to be fixed, and a null model that does not
impose this constraint is more appropriate for mining results from transactional
datasets than one that does.

\section{Sampling Without Distortion}\label{sec:diffusr}

\subsection{A First Algorithm}\label{sec:diffusr:naive}

To warm up, we first present $\naivealgo$ (the \textsc{N} stands for
``na\"{\i}ve''), a relatively simple algorithm to sample \emph{without
distortion} from a SLISP null model $\nullmodel = (\nullset,\nullprob)$
associated to an observed dataset $\odataset$. \naivealgo\ uses MCMC with MH to
sample from $\matrices$, the set of binary matrices also considered by \gioalgo\
(\cref{sec:gionis}). The neighborhood structure over $\matrices$ is the same as
in \gioalgo, as is the distribution $\neighprob_M$, $M \in \matrices$, which is
the uniform distribution over the out-neighbors of $M$. The intuition behind
\naivealgo\ is that, if, for each dataset $\dataset \in \nullset$, we can
compute the number $\copiesnum{\dataset}$ of matrices $M \in \matrices$ such
that $\mattodat{M} = \dataset$, then we can remove the distortion that the
presence of these ``copies'' introduces. The following result gives the
expression for $\copiesnum{\dataset}$.

\begin{lemma}\label{lem:numcopies}
  For any dataset $\dataset \in \nullset$, let $L_\dataset \doteq \{\ell_1,
  \dotsc, \ell_{z_\dataset}\}$ be the set of the $z_\dataset$ distinct lengths
  of the transactions in $\dataset$. For each $1 \le i \le z_\dataset$, let
  $T_i$ be the \emph{bag} of transactions of length $\ell_i$ in $\dataset$.
  Let $\bar{T}_i = \{\tau_{i,1}, \dotsc, \tau_{i,h_i}\}$ be the \emph{set} of
  transactions of length $\ell_i$ in $\dataset$, i.e., without duplicates. For
  each $1 \le j \le h_i$, let $W_{i,j} \doteq \{ t' \in T_i \suchthat  t' =
  \tau_{i,j} \}$ be the \emph{bag} of transactions equal to $\tau_{i,j}$ in
  $T_i$ (including $\tau_{i,j}$). Then, the number of matrices $M$ in
  $\matrices$ such that $\mattodat{M} = \dataset$ is
  \begin{equation}\label{eq:copiesnum}
    \copiesnum{\dataset} \doteq \prod_{i=1}^{z_\dataset}
    \underbracket{\binom{\card{T_i}}{\card{W_{i,1}}, \dotsc,
    \card{W_{i,h_i}}}}_{\text{multinomial coefficient}}
    = \prod_{i=1}^{z_\dataset} \frac{\card{T_i}!}{\prod_{j=1}^{h_i}
    \card{W_{i,j}}!} \enspace.
  \end{equation}
\end{lemma}

\begin{proof}
  Recall that $\matrices$ depends on the observed dataset $\odataset$ and on the
  arbitrary ordering of its transactions chosen by \gioalgo, as the ordering
  fixes the row-sums $\rowsum{i}$, $1 \le i \le \rowsnum$ of the matrices in
  $\matrices$. In other words, it fixes the row indices of rows corresponding to
  transactions of length $\ell_i$, $1 \le i \le z_\dataset$, of
  $\dataset$. Thus, the number of different ways in which the transactions of
  $\dataset$ can be assigned to the rows of a matrix in $\matrices$ is the
  product, over the lengths in $L_\dataset$, of the number $q_i$ of different
  ways in which the transactions in $T_i$ can be assigned, i.e.,
  \[
    \copiesnum{\dataset} = \prod_{i=1}^{z_\dataset} q_i \enspace.
  \]
  Thus, we only have to argue that
  \[
    q_i = \binom{\card{T_i}}{\card{W_{i,1}}, \dotsc,
    \card{W_{i,h_i}}},
  \]
  which is true because the multinomial coefficient $\binom{n}{k_1,\dotsc,k_h}$
  is the number of different permutations of a bag containing $n$ objects such
  that $k_1$ objects are indistinguishable among themselves and of type 1, $k_2$
  objects are indistinguishable among themselves and of type 2, and so
  on~\citep[Eq.~1.22]{Stanley11}.
\end{proof}

The core idea of \naivealgo\ is that the probability $\nullprob(\dataset)$ of
sampling $\dataset$ should be ``spread'' among the $\copiesnum{\dataset}$
matrices $M \in \matrices$ s.t.\ $\mattodat{M} = \dataset$. Thus, \naivealgo\
uses MCMC with MH on the state space $\matrices$, but with the desired stationary
distribution
\begin{equation}\label{eq:naivestatprob}
  \samplprob(M) \doteq \frac{\nullprob(\mattodat{M})}{\copiesnum{\mattodat{M}}}
    \enspace.
  \end{equation}
As mentioned, the probability distribution over the out-neighbors of a matrix is
the uniform as in \gioalgo, so \naivealgo\ can also reuse \gioalgo's
procedure to sample an out-neighbor $M''$ of a matrix $M'$~\citep[Alg.\
2]{GionisMMT07}. Computing $\copiesnum{\mattodat{M''}}$ using
$\copiesnum{\mattodat{M'}}$ is relatively straightforward, knowing the swap that
allows to obtain $M''$ from $M'$, thus only the number of copies for the initial
state $X_0$ corresponding to $\odataset$ has to be computed from scratch using
the definition in~\eqref{eq:copiesnum}. Using the notation from the statement of
\cref{lem:numcopies}, given a transaction $t \in \mattodat{M'}$, suppose $t \in
T_i$ for $1 \leq i \leq z_{\mattodat{M'}}$. Further suppose $t = \tau_{i, j} \in
\bar{T}_i$, where $1 \leq j \leq h_i$. Let $\mathsf{net}$ be a dictionary that
maps each different transaction $t \in \mattodat{M'}$ to $\card{W_{i, j}}$,
i.e., the size of the bag of transactions equal to $t$ (including $t$). This
data structure is easy to initialize and keep up to date. We can then obtain
$\copiesnum{\mattodat{M'}}$ from $\copiesnum{\mattodat{M''}}$ as shown in
\cref{algo:getcopiesnumneigh}, which leverages the fact that
$\copiesnum{\mattodat{M'}} = \copiesnum{\mattodat{M''}}$ if $\mattodat{M''} =
\mattodat{M'}$ (\cref{algline:samedat}), and the definition of the multinomial
to greatly simplify the computation
(lines~\ref{algline:updatestart}--\ref{algline:updateend}).

\begin{algorithm}[ht]
  \caption{Computing $\copiesnum{\mattodat{M''}}$ from
  $\copiesnum{\mattodat{M'}}$}\label{algo:getcopiesnumneigh}
  \DontPrintSemicolon%

  \SetKwData{NumEqTransac}{net}

  \KwIn{Value $\copiesnum{\mattodat{M'}}$, valid swap $((t_a,a), (t_b,b))$ from
  $\mattodat{M'}$ to $\mattodat{M''}$, dictionary $\NumEqTransac$}

  \KwOut{$\copiesnum{\mattodat{M''}}$}

  $\bar{t}_a \gets (t_a \setminus \{a\}) \cup \{b\}$,  $\bar{t}_b \gets (t_b
  \setminus \{b\}) \cup \{a\}$\;

  \lIf{$t_a =
    \bar{t}_b$}{\Return{$\copiesnum{\mattodat{M'}}$}}\label{algline:samedat}

  \ForEach{$i \in \{a,b\}$}{\label{algline:updatestart}
    \leIf{\NumEqTransac\ has key $\bar{t}_i$}{$\beta_i \gets
      \NumEqTransac[\bar{t}_i]$}{$\beta_i \gets 0$}
  } % \ForEach{$i \in \{a,b\}$}{

  \Return{$\copiesnum{\mattodat{M'}} \frac{\NumEqTransac[t_a]
        \NumEqTransac[t_b]}{(\beta_a + 1) (\beta_b +
      1)}$}\label{algline:updateend}
\end{algorithm}

\naivealgo\ obtains a matrix $M$ by running MCMC sampling with MH with the
inputs just described, and outputs the dataset $\mattodat{M}$.

\begin{theorem}\label{thm:correctnaive}
  The output of \naivealgo\ is a sample from $\nullset$ distributed according to
  $\nullprob$.
\end{theorem}

\begin{proof}
 A dataset $\dataset  \in \nullset$ is returned in output by \naivealgo\ iff a
 matrix $M$ such that $\mattodat{M} = \dataset$ is sampled. There are
 $\copiesnum{\dataset}$ such matrices $M$, each with a probability
 $\samplprob(M)$ as in~\eqref{eq:naivestatprob} to be sampled, from the
 properties of MCMC sampling with MH\@. Thus, the probability of returning
 $\dataset$ is exactly $\nullprob(\dataset$).
\end{proof}

\subsection{A Refined Algorithm}\label{sec:diffusr:refined}

We now discuss a more refined algorithm \refalgo\ (the \textsc{R} is for
``refined'') to sample datasets from a SLISP null model $\nullmodel = (\nullset,
\nullprob)$. \refalgo\ is also based on MCMC sampling with MH, but uses a Markov
chain with a different state space and neighborhood structure than \gioalgo\ and
\naivealgo.

\refalgo\ \emph{directly} removes the distortion from the state space, rather
than counteracting it at the level of the stationary distribution of the Markov
chain like \naivealgo\ does.

The state space of $\refalgo$ is the dataset null set $\nullset$ itself, without
any representation of the datasets as matrices or imposition of ordering of the
transactions in a dataset which  is irrelevant for many knowledge discovery
tasks (see end of \cref{sec:gionis}).

% 20220124 MR: We keep this for the journal version.
%\todo[for=Everybody,date=12/11]{Consider the possibility of allowing swaps
%  between transactions that differ in length by one, where only one item moves,
%from the longer to the shorter.}

In the initial neighborhood structure, there is an edge from a dataset $\dataset' \in
\nullset$ to another dataset $\dataset'' \in \nullset$ if there exist two transactions
$t_a, t_b \in \dataset'$ such that \textit{(1)} neither $t_a \setminus t_b$ nor
$t_b \setminus t_a$ are empty, and at least one of these two asymmetric set
differences contains strictly more than one item; and \textit{(2)}
there are items $a \in t_a \setminus t_b$ and $b \in t_b \setminus
t_a$ such that if we let $\bar{t}_a \doteq (t_a \setminus \{a\}) \cup \{b\}$
and $\bar{t}_b \doteq (t_b \setminus \{b\}) \cup \{a\}$, then it holds that
$\dataset'' = ( \dataset' \setminus \{t_a, t_b\} ) \cup \{ \bar{t}_a, \bar{t}_b
\}$, i.e., $\dataset''$ can be obtained from $\dataset'$ by swapping a pair of
items between two transactions that are not one a subset (proper or improper) of
the other, and each of which contains only one of the two items. This operation
can be seen as a \emph{dataset-oriented} version of the \emph{swap} at the basis
of the swap randomization process used by \gioalgo, thus we still refer to it as
\emph{swap}. A swap can be identified as an unordered pair $((t_a,a), (t_b,b))$.
The condition on one of the asymmetric set differences containing strictly more
than one item ensures that a swap always ``leads'' to a different dataset, i.e.,
there are no swaps from $\dataset'$ to $\dataset'$. On the other hand, there may
be multiple swaps that lead from $\dataset'$ to a different $\dataset''$. We
denote the number of such swaps with $\spairsnum{\dataset'}{\dataset''}$ and
show, in \cref{lem:spairsnum,corol:spairsnumneigh}, expressions for this
quantity and for $\spairsnum{\dataset''}{\dataset'}$ respectively, as both are
needed by \refalgo, as we explain later.

For any $t_1, t_2 \in \dataset'$, let $\spairsfactor(t_1,t_2)\doteq 2$ if
$\card{t_1} = \card{t_2}$ and $\card{t_1 \setminus t_2} = \card{t_2 \setminus
t_1} = 2$, and $\spairsfactor(t_1,t_2) \doteq 1$ otherwise.

\begin{lemma}\label{lem:spairsnum}
  Let $((t_a,a), (t_b,b))$ be a swap from $\dataset'$ to $\dataset''$. Then,
  \[
    \spairsnum{\dataset'}{\dataset''} = \spairsfactor(t_a,t_b) \card{\{t \in
    \dataset' \suchthat t = t_a\}} \cdot \card{\{t \in \dataset' \suchthat t =
     t_b\}} \enspace.
  \]
\end{lemma}

\begin{proof}
  We start by showing that, independently from the value of
  $\spairsfactor(t_a,t_b)$, all the swaps from $\dataset'$ to $\dataset''$ must
  involve transactions that are identical to $t_a$ and $t_b$, i.e, be in the
  form $((t_a,x),(t_b,y))$, for some $x,y\in \items$. Let $((t_c,c), (t_d,d))$
  be a swap from $\dataset'$ to $\dataset''$. We want to show that $((t_c,c),
  (t_d,d)) = ((t_a,a),(t_b,b))$.  Let $\bar{t}_a = (t_a \setminus \{a\}) \cup
  \{b\}$, $\bar{t}_b = (t_b \setminus \{b\}) \cup \{a\}$, $\bar{t}_c = (t_c
  \setminus \{c\}) \cup \{d\}$, and $\bar{t}_d = (t_d \setminus \{d\}) \cup
  \{c\}$. Then,
  \[
    (\dataset' \setminus \{ t_a, t_b \}) \cup \{ \bar{t}_a, \bar{t}_b \} =
    (\dataset' \setminus \{ t_c, t_d \}) \cup \{ \bar{t}_c, \bar{t}_d \}
  \]
  since both sides are equal to $\dataset''$. Since datasets are \emph{bags}, the
  operations of difference and union are effectively one the inverse of the
  other. Thus, we can write
  \[
    \dataset' \cup \{ \bar{t}_a, \bar{t}_b \} \cup \{ t_c, t_d \} = \dataset'
    \cup \{ \bar{t}_c, \bar{t}_d \} \cup \{ t_a, t_b \} \enspace.
  \]
  We can remove $\dataset'$ from both sides to get
  \begin{equation}\label{eq:spairsnumtech}
    \{ \bar{t}_a, \bar{t}_b, t_c, t_d \} = \{ \bar{t}_c, \bar{t}_d, t_a, t_b \}
    \enspace.
  \end{equation}
  By definition of a swap, it must be $t_a \neq \bar{t}_a$ and $t_a \neq
  \bar{t}_b$, thus it must be either $t_a = t_c$ or $t_a = t_d$, and similarly
  for $t_b$.

  Assume now that $\card{t_a} \neq \card{t_b}$, then only one between $t_a =
  t_c$ and $t_a = t_d$ is actually possible so, w.l.o.g., let $t_a = t_c$ and
  $t_b = t_d$. Then from these facts and~\eqref{eq:spairsnumtech}, it must be
  $\{ \bar{t}_a, \bar{t}_b \} = \{ \bar{t}_c, \bar{t}_d \}$, thus either
  $\bar{t}_a = \bar{t}_c$ or $\bar{t}_a = \bar{t}_d$. Since $\card{\bar{t}_a} =
  \card{t_a} = \card{t_c} = \card{\bar{t}_c}$ and $\card{\bar{t}_d} =
  \card{t_d} = \card{t_b}$, then it can only be $\bar{t}_a = \bar{t}_c$, which
  implies $c = a$, and similarly it must be $b = d$. Thus, if $\card{t_a} \neq
  \card{t_b}$, then all swaps from $\dataset'$ to $\dataset''$ are equal to
  $((t_a,a), (t_b,b))$, which implies the thesis for this case.

  Assume now that $\card{t_a} = \card{t_b}$ but $\card{t_a \setminus t_b}$ and
  $\card{t_b \setminus t_a}$ are different than 2 (the two asymmetric set
  differences must have the same size, since the two sets have the same size).
  From the first part of the proof, we have that it must be either $t_a = t_c$
  or $t_a = t_d$, and similarly for $t_b$. W.l.o.g., let $t_a = t_c$ and $t_b =
  t_d$.  If $\card{t_a \setminus t_b} = \card{t_b \setminus t_a} = 1$, then $a$
  and $b$ are the only two items that can be swapped, so it must be $c = a$ and
  $b = d$. Thus, in this specific subcase, all swaps from $\dataset'$ to
  $\dataset''$ are equal to $((t_a,a), (t_b,b))$, which implies the thesis for
  this case. Assume now that $\card{t_a \setminus t_b} = \card{t_b \setminus
  t_a} > 2$.  From these facts and~\eqref{eq:spairsnumtech}, it must be $\{
  \bar{t}_a, \bar{t}_b \} = \{ \bar{t}_c, \bar{t}_d \}$, thus either $\bar{t}_a
  = \bar{t}_c$ or $\bar{t}_a = \bar{t}_d$. We now show that it must be
  $\bar{t}_a = \bar{t}_c$. Assume by contradiction that $\bar{t}_a = \bar{t}_d$.
  Since $t_c = t_a$, it holds $\bar{t}_a = t_c \setminus \{a\} \cup \{b\}$.
  Thus, it must be
  \[
    (t_c \setminus \{a\}) \cup \{b\} = (t_d \setminus \{d\}) \cup \{c\} \enspace.
  \]
  Since $a, c \in t_c$ and $b \notin t_c$, by taking the asymmetric set
  differences between each side of the above identity and $t_c$ we get
  \[
    \{ b \} = (t_d \setminus \{d \}) \setminus t_c
  \]
  which means that $t_d \setminus t_c  = t_b \setminus t_a = \{b, d\}$, i.e.,
  this set difference has size equal to 2, which is a contradiction since we
  assumed that $\card{t_b \setminus t_a} > 2$. Thus, it must be $\bar{t}_a =
  \bar{t}_c$, which implies $c = a$, and similarly it must be $b = d$. Thus, all
  swaps from $\dataset'$ to $\dataset''$ are equal to $((t_a,a), (t_b,b))$,
  which implies the thesis for this case.

  We have therefore shown that the thesis is true for the case
  $\spairsfactor(t_a,t_b)=1$. Consider now the other case, which means that
  $\card{t_a} = \card{t_b}$ and $\card{t_a \setminus t_b} = \card{t_b \setminus
  t_a} = 2$. W.l.o.g., let $t_a \setminus t_b = \{a, z\}$ and $t_b \setminus t_a
  = \{b, w\}$.  It is easy to see that the swaps $((t_a,a), (t_b,b))$ and
  $((t_a,z), (t_b,w))$ lead to the same dataset $\dataset''$, while the other
  two swaps $((t_a,a), (t_b,w))$ $((t_a,z), (t_b,b))$ lead to a different
  dataset. Thus, there are $\spairsfactor(t_a,t_b)=2$ swaps from $\dataset'$ to
  $\dataset''$ involving the transactions $t_a$ and $t_b$. From the first part
  of the proof, we have that all swaps from $\dataset'$ to $\dataset''$ must
  involve transactions identical to $t_a$ and $t_b$, hence we obtain the thesis
  for this case.
\end{proof}

\begin{corollary}\label{corol:spairsnumneigh}
  Let $((t_a,a), (t_b,b))$ be a swap from $\dataset'$ to $\dataset''$, and
  $\bar{t}_a \doteq (t_a \setminus \{a\}) \cup \{b\}$ and $\bar{t}_b \doteq (t_b
  \setminus \{b\}) \cup \{a\}$. Then, $\spairsnum{\dataset''}{\dataset'}$
    $= \spairsfactor(t_a,t_b)
    (\card{\{t \in \dataset' \suchthat t = \bar{t}_a\}} + 1)  (\card{\{t \in
    \dataset' \suchthat t = \bar{t}_b\}} + 1)$.
\end{corollary}

We need the following result on the number of valid swaps from a dataset
$\dataset$.

\begin{theorem}\label{thm:totspairsnumdat}
  Let $M_\dataset$ be any matrix representation of $\dataset$
  (\cref{sec:gionis}). Then,
  \begin{equation}\label{eq:totspairsnumdat}
    \totspairsnumdat{\dataset} =
    \underbracket{\totspairsnummat{M_\dataset}}_{\text{\cref{thm:totspairsnummat}}}
    - \selfspairsnum{\dataset},
  \end{equation}
  where
  \begin{equation}\label{eq:selfspairsnum}
    \selfspairsnum{\dataset} \doteq \frac{1}{2} \card{\{ (t_a,t_b) \in \dataset
    \times \dataset \suchthat \card{t_a} = \card{t_b} \wedge \card{t_a \setminus
    t_b} = \card{t_b \setminus t_a} = 1\}} \enspace.
  \end{equation}
\end{theorem}

\begin{proof}
  Let $((t_a, a), (t_b, b))$ be any of the $\totspairsnummat{M_\dataset}$
  swaps from $M_\dataset$ to any $M$ of its neighbor matrices in the Markov
  chain used by \gioalgo. From the definitions of ``swap'' for \gioalgo\ and for
  \refalgo, it follows that $((t_a, a), (t_b, b))$ is a valid swap for
  $\refalgo$ iff $\mattodat{M} \neq \dataset$, i.e., if the dataset
  corresponding to $M$ is not $\dataset$ itself. The number of valid
  swaps from $\dataset$ is therefore $\totspairsnummat{M_\dataset}$ minus the
  total number of swaps from $M_\dataset$ to any $M$ of its neighbors with
  $\mattodat{M} = \dataset$. We now show that the number of such
  ``self-swaps'' is $\selfspairsnum{\dataset}$.

  For a neighbor $M \neq M_\dataset$ of $M_\dataset$ to have $\mattodat{M} =
  \dataset$, it must be the case that there is a swap $((t_a, a), (t_b, b))$
  such that
  \[
    (t_a \setminus \{a\}) \cup \{b\} = t_b\ \text{and}\ (t_b \setminus \{b\})
    \cup \{a\}=t_a \enspace.
  \]
  Since $a \in t_a \setminus t_b$ and $b \in t_b \setminus t_a$, the above is
  possible iff $\card{t_a} = \card{t_b}$ and $\{a\} = t_a \setminus t_b$ and
  $\{b\} = t_b \setminus t_a$. The number of such \emph{unordered} pairs of
  transactions (i.e., the number of self-swaps) is as
  in~\eqref{eq:selfspairsnum}, where the factor $\sfrac{1}{2}$ is to correct for
  the fact that the considered set contains \emph{ordered} pairs of
  transactions.
\end{proof}

\refalgo\ uses MCMC sampling with MH to sample according to $\nullprob$. Let
$\dataset' \in \nullset$ be the current state of the chain. The
distribution $\neighprob_{\dataset'}$,  according to
which MH samples a neighbor $\dataset''$ of $\dataset'$ is
\begin{equation}\label{eq:refinedneighprob} \neighprob_{\dataset'}(\dataset'')
\doteq \frac{\spairsnum{\dataset'}{\dataset''}}{\totspairsnumdat{\dataset'}}
\enspace. \end{equation}
Sampling a neighbor of $\dataset'$ according to the distribution
$\neighprob_{\dataset'}$ is straightforward (see
\cref{algo:samplerefinedneighprob}). Let $\spairs$ be the bag of ordered pairs
$(t,i)$ for every $t \in \dataset'$ and $i \in t$. We can draw two pairs $(t_a,
a)$ and $(t_b, b)$ independently and uniformly at random from $\spairs$ and
check whether the unordered pair $((t_a, a), (t_b, b))$ is a valid swap, i.e.,
it satisfies all the requirements for $t_a$, $t_b$, $a$, and $b$ in the
definition of a swap (there are pairs that are not valid swaps, e.g., those
involving the same transaction). In this case the sampled neighbor $\dataset''$
is the one obtained by performing the swap, otherwise two more elements are
drawn from $\spairs$ until a valid swap is found.

\begin{algorithm}[hb]
  \caption{Sampling according to the refined neighborhood distribution
  $\neighprob_{\dataset'}(\dataset'')$}\label{algo:samplerefinedneighprob}
  \DontPrintSemicolon%

  \SetKwRepeat{Do}{do}{while}

  \KwIn{bag $\spairs \doteq \{(t,i) \suchthat t \in \dataset, i \in t\}$}

  \KwOut{valid swap $((t_a,a), (t_b,b))$ from $\dataset'$ to $\dataset''$}

  \Do{$(a \in t_b) \vee (b \in t_a) \vee (t_a \setminus \{a\} = t_b \setminus
  \{b\})$}{
    $(t_a,a), (t_b,b) \gets$ uniform independent samples from $\spairs$
  } % \Do{$(a \in t_b) \vee (b \in t_a) \vee (t_a \setminus \{a\} = t_b \setminus \{b\})$}{

  \Return{$((t_a,a), (t_b,b))$}
\end{algorithm}

\begin{lemma}\label{lem:sampleneighbor}
  Let $\dataset''$ be a neighbor of $\dataset' \in \nullset$. The probability
  that the above procedure outputs $\dataset''$ is
  $\neighprob_{\dataset'}(\dataset'')$.
\end{lemma}

\begin{proof}
  The procedure keeps sampling candidate swaps (i.e., pairs of elements of
  $\spairs$) until it finds one that is a valid swap. Since each element of
  $\spairs$ is sampled independently and uniformly at random from $\spairs$,
  then the candidate swap is chosen uniformly at random among all candidate
  swaps, thus, if it is valid, is also chosen uniformly at random among all
  valid swaps, i.e., each valid swap has a probability of
  $1/\totspairsnumdat{\dataset'}$ of being chosen among all valid swaps, as
  there is one and only one pair of elements of $\spairs$ for each valid swap.
  $\dataset''$ is output whenever the procedure chooses one of the
  $\spairsnum{\dataset'}{\dataset''}$ valid swaps leading to it from
  $\dataset'$. Thus, the probability of outputting $\dataset''$ is the sum of
  the probabilities of choosing each of these swaps, hence the thesis.
\end{proof}

Assuming the current state of the Markov chain is $\dataset'$, by plugging the
definition of $\neighprob_{\dataset'}$ from~\eqref{eq:refinedneighprob}
into~\eqref{eq:metropolis} (using $\samplprob=\nullprob$), we get that the
probability MH accepts as the next state a neighbor $\dataset''$ drawn
according to $\neighprob_{\dataset'}$ is
\begin{equation}\label{eq:refinedacceptprob} \min \left\{1,
    \frac{\nullprob(\dataset'') \spairsnum{\dataset''}{\dataset'}
\totspairsnumdat{\dataset'}}{\nullprob(\dataset')
\spairsnum{\dataset'}{\dataset''}
\totspairsnumdat{\dataset''}} \right\} \enspace.
\end{equation}
\refalgo\ needs data structures and procedures to compute all the necessary
quantities. More precisely, \refalgo\ initializes some data structures at the
beginning of its execution, and uses and updates them to select the successive
states of the Markov chain  (which starts at $\odataset)$. First, the bag
$\spairs \doteq \{ (t,i) \suchthat t \in \dataset', i \in t\}$ is built in the
obvious way, with $\dataset' = \odataset$. This bag is all that is needed to
sample a neighbor from the current state $\dataset'$ according to the
distribution $\neighprob_{\dataset'}$. Updating $\spairs$ after moving to a new
state $\dataset''$ is straightforward: only pairs involving the transactions
participating in the performed swap are removed (for the transactions before the
swap) or added (for the transactions after the swap). Secondly, \refalgo\ builds
a dictionary $\hashmapsym$ s.t.\ for each transaction $t \in \odataset$, \[
\hashmap{t} \doteq \card{\{t' \in \odataset \suchthat t' = t\}} \] is the
number of transactions in $\odataset$ equal to $t$, including $t$. Computing
$\spairsnum{\dataset'}{\dataset''}$ and $\spairsnum{\dataset''}{\dataset'}$ for
any dataset $\dataset'$ and any $\dataset''$ of its neighbors is
straightforward using the expressions of these quantities from
\cref{lem:spairsnum,corol:spairsnumneigh} and the dictionary $\hashmapsym$.
Updating $\hashmapsym$ after moving to a new state is easy, requiring changes
only to the key-value pairs where the key is a transaction involved in the swap,
either before or after the swap. The last quantities to discuss are
$\totspairsnummat{M_{\dataset'}}$ and $\selfspairsnum{\dataset'}$
from~\eqref{eq:totspairsnumdat}. \Citet[Thm.\ 4.3, Corol.\ 4.4]{GionisMMT07}
give procedures to compute $\totspairsnummat{M_{\dataset'}}$ and, using this
quantity, $\totspairsnummat{M_{\dataset''}}$, thus we can focus on
$\selfspairsnum{\dataset'}$ and how to obtain $\selfspairsnum{\dataset''}$ from
it. Let $\textsf{TL}$ be a dictionary that maps each different $\ell \in
\mathbb{N}$ for which there is at least one transaction $t \in \odataset$ with
$\card{t} = \ell$ to the \emph{bag} of transactions in $\odataset$ with length
$\ell$. Initializing this data structure given $\odataset$ is straightforward,
and at the same time one can also compute $\selfspairsnum{\odataset}$.  Given
$\mathsf{TL}$ and $\selfspairsnum{\dataset'}$ for the current state $\dataset'$,
we can compute $\selfspairsnum{\dataset''}$ for a neighbor $\dataset''$ obtained
by performing a swap $((t_a,a),(t_b,b))$ from $\dataset'$ as follows (pseudocode
in \cref{algo:getselfspairsnumneigh}). First, a variable $z$ is
initialized to $\selfspairsnum{\dataset'}$ (\cref{algline:zinit}). Then, for
each $t \in \{t_a,t_b\}$ we iterate over $\mathsf{TL}[\card{t}] \setminus
\{t_a,t_b\}$, i.e., the bag of transactions of length $\card{t}$ that are
neither $t_a$ nor $t_b$. Let $t^*$ be a transaction in this bag, and let $d^*$ be
$\card{(t \setminus t^*) \cup (t^* \setminus t)}$, i.e., the number of items
that are either only in $t$ or only in $t^*$ (\cref{algline:dinit}). Then, the
algorithm checks if $d^*$ is not larger than four
(\cref{algline:notmorethanfour}): when $d^* > 4$, then there is no
self-swap involving $t$ and $t^*$ from $\dataset'$ to itself, nor there is one
from $\dataset''$ to itself, thus there is nothing to do in this case. If
instead $d^* \le 4$, the procedure computes the number of items that are
either only in $t^*$ or in the transaction $\bar{t}$ obtained from $t$ after
the swap (i.e., if $t = t_a$, then $\bar{t} = (t_a \setminus \{a\}) \cup
\{b\}$, and similarly if $t = t_b$): for each $i \in \{a,b\}$
(\cref{algline:foreachitem}), if $i$ appears in both $t$ and $t^*$ or does not
appear in either, then $d$ is increased by one (\cref{algline:bothorneither}),
as that means that $i$ will appear in exactly one of $\bar{t}$ and $t^*$ after
the swap, otherwise $d$ is decreased by one (\cref{algline:decrease}), because
$i$ will either appear or not appear in both $\bar{t}$ and $t^*$ after the
swap. Then, if $d$ equals $2$ (resp.\ is not equal to $2)$ and $d^*$ is not
equal to $2$ (resp.\ equals $2$), it means that there is an additional (resp.\
one fewer) invalid self-swap that would lead from $\dataset''$ to itself, and
the variable $z$ is updated accordingly
(lines~\ref{algline:zplusone}--\ref{algline:zminusone}).

\begin{algorithm}[htb]
  \caption{Computing $\selfspairsnum{\dataset''}$ from
  $\selfspairsnum{\dataset'}$}\label{algo:getselfspairsnumneigh}
  \DontPrintSemicolon%
  \SetKwData{TransactionsOfLength}{TL}
  \KwIn{Value $\selfspairsnum{\dataset'}$, valid swap $((t_a,a),(t_b,b))$ from
  $\dataset'$ to $\dataset''$, dictionary $\TransactionsOfLength$}
  \KwOut{$\selfspairsnum{\dataset''}$}
  $z \gets \selfspairsnum{\dataset'}$\;\label{algline:zinit}
  \ForEach{$t \in \{t_a, t_b\}$}{
    \ForEach{$t^* \in \TransactionsOfLength[\card{t}] \setminus \{t_a, t_b\}$}{\label{algline:tlloop}
      $d^* \gets \card{(t \setminus t^*) \cup (t^* \setminus t)}$\;\label{algline:dinit}
      \If{$d^* \le 4$}{\label{algline:notmorethanfour}
        $d \gets d^*$\;
        \ForEach{$i \in \{a,b\}$}{\label{algline:foreachitem}
          \lIf{$i \in t \cap t^* \vee i \notin t \cup t^*$}{$d \gets d +
            1$}\label{algline:bothorneither}
          \lElse{$d \gets d - 1$}\label{algline:decrease}
        } % end \ForEach{$i \in \{a,b\}$}
        \lIf{$d = 2 \wedge d^* \neq 2$}{$z \gets z +
          1$}\label{algline:zplusone}
        \lElseIf{$d \neq 2 \wedge d^* = 2$}{$z \gets z -
        1$}\label{algline:zminusone}
      } % end \If{$d > 4$}
    } % end ForEach{$t^* \in \TransactionsOfLength[\card{t}]$}
  } % end ForEach{$t \in \{t_a, t_b\}$}
  \Return{$z$}
\end{algorithm}

\section{Extensions and Discussion}\label{sec:extensions}

In \cref{sec:exper}, we use \algo\ to test the significance of the number
$\card{\fis{\thresh}{\odataset}}$ of frequent itemsets (as described in
\cref{sec:prelims:significant}). This is a relatively simple task that we choose
to make the presentation self-contained and accessible: our algorithms can be
used for assessing the statistical significance of the results of many other
tasks defined on transactional datasets, including significant pattern
mining~\citep{PellegrinaRV19b}. \citet{HamalainenW19} discuss many such tasks,
as do \citet{GionisMMT07}, who show how to use \gioalgo\ for them. \algo\ can be
used as a drop-in replacement of \gioalgo\ in these cases.

Algorithms for sampling different kinds of datasets for knowledge discovery
tasks also incur a distortion of the sample space similar to the one we
discussed for \gioalgo. For example, \citet{TononV19} present
swap-randomization methods to draw \emph{sequential} datasets (approximately)
uniformly at random from a model, which are then used for mining significant
frequent sequences. Their sampling methods, being similar to \gioalgo, suffer
from a similar distortion. It is straightforward to develop variants of \algo\
for sampling sequential datasets and warrants future work. Similar extensions
should also be possible for other kinds of patterns.

A transactional dataset $\dataset$ can be seen as a bipartite graph $G_\dataset$
with one vertex for each item $i \in \items$ on one side, and one vertex for
each transaction $t \in \dataset$ on the other side, and such that there is an
edge $(i,t)$ iff $i \in t$ \citep[Sect.\ 4.1]{GionisMMT07}. \gioalgo\ can be
seen as an algorithm for sampling, uniformly, bipartite graphs with the same
degree distribution as $G_\dataset$. In this setting, the distortion means that
two bipartite graphs that are identical up to permutations of the identifiers of
the transaction vertices (a weak form of graph isomorphism) would be considered
different graphs, which may or may not be desired by the user, who is the
ultimate decision maker and should be made aware of the consequences of choosing
different null models. \algo\ can be used to fix this distortion.

Is distortion always undesirable? If the user's goal is to sample from a null
model where different orderings of the transactions correspond to different
datasets, then there is no distortion in this case and the question is moot.
However, distortion is undesirable if the goal is to sample from a SLISP null
model. Distortion is \emph{always} present and undesirable when the user samples
according to a null model distribution $\nullprob$ from a null set $X$, but
their true objective is to sample according to $\nullprob$ from a null set $Y$,
and there does \emph{not} exist an bijective function between $X$ and $Y$.

One limitation of this work is that we do not show an upper bound to the
\emph{mixing time} $\mathsf{t}(\varepsilon$), $\varepsilon \in (0,1)$ of the
Markov chains of our algorithms, i.e., the number of steps needed for the
distribution of the state $X_t$ to have total variation distance at most
$\varepsilon$ from the desired stationary distribution
$\nullprob$~\citep[Ch.\ 10]{MitzenmacherU05}. Such a bound is not available for
\gioalgo\ either, because using the MH approach makes such a derivation
particularly challenging. We conjecture that better bounds to
$\mathsf{t}(\varepsilon)$ can be derived for \refalgo\ than for \naivealgo,
thanks to its smaller and more connected state space.

Another limitation, in common with all previous work, is in the definition of
the SLISP null model: while preserving the size, transaction lengths, and item
supports is crucial, it may not be sufficient for the null set $\nullset$ to be
representative of the unknown process. Defining more descriptive null models and
efficient procedures to sample from them is a interesting research direction.
