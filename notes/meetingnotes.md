# Notes

## 09-06-21: Meeting

- "From the reversibility properties, it follows that the probability
  of each state in such stationary distribution is proportional to the
  degree of the states" (Tonon and Vandin, Page 5). Proof for this is
  in 7.13 theorem of Probability and Computing textbook.

## 09-16-21: Meeting

- Properties to preserve:
  - The utility of an item in the database.
  - The distribution of the transaction lengths in the database.
  - The distribution of the transaction utilities in the database.
- TODO:
  - Think about other properties to preserve.
  - Come up with methods that preserve at least 1 of the properties
    above.
  - Try to make methods as minimal as possible such that they don't
    preserve other properties.

## 09-22-21: Meeting

- We can think of our dataset as a sample in the population of
  datasets that is generated by some process.
- We estimate our p-value with
  $\frac{1}{T + 1} (1 + \\sum\_{i = 1}^T 1\[u\_{D\_i}(X) \\geq u\_D(A)\])$.
  We use $T + 1$ because we are generating $T$ random datasets and then we also
  count the dataset $D$ we started with.
- Let's say we generate a random dataset and we see that itemset $X$
  is a high utility itemset. If we compared the utility of $X$ to our
  null model, we would flag $X$ as statistically significant, even
  though it is not. This is our false positive rate.

## 09-29-21: Meeting

- Questions:
  - Go over proof
  - For the self loop method, it seems like we are staying in the
    same state for a while if there are many instances where items
    can't swap with each other. So why would we still have a uniform
    stationary distribution?
  - We can prove that our method generates a uniform stationary
    distribution. But how do we know that it is a uniform
    distribution over all the datasets with our properties?
- Notes:
  - Number of valid swaps stays the same, so the degree of each
    state is the same. Proof? (Note: this is wrong)
  - Prove that things are constants... (Note: don't need this)
  - Rows sum to one (as they normaly do), and columns sum to 1. This
    is a doubly stochastic matrix. And the stationary dist of this
    matrix is uniform.
  - Now, how to prove that the number of nonvalid swaps is constant
    across states? (Note: don't need this)
- TODO:
  - Send proof graph to Matteo

## 10-02-21: Email

- Since all swaps are reversible, our transition probability matrix
  $\\mathbf{P}$ is symmetric because $P\_{i, j} = P\_{j, i}$ for all
  states $i, j$. With a symmetric matrix that has rows that sum to 1,
  we know that its columns also sum to 1. Thus, $\\mathbf{P}$ is
  doubly stochastic, so our stationary distribution is uniform.
- TODO:
  - "I don't think that two datasets built over the same set of
    transactions but for which the ordering of transactions of the
    same length is different should count as two different datasets.
    It would be nice to see if we can remove this "redundancy" in
    the null model."

## 10-06-21: Meeting

- If we take frequent itemsets as an example, a state could lead to two states
  that are the same dataset if we don't care about order or the same dataset
  if we do care about order. But if we don't care about order (which we
  normally don't) then we would essentially double count a dataset
- TODO:
  - Does Gionis consider datasets that are ordered the same
  - Are we doing ordered, unordered pairs?
  - Either show a counter example, or a proof that their method
    works
  - Redo example with proper probabilities

## 10-13-21: Meeting

- Matteo: each swappable pair is selected with probability 1 / (# swappable
  pairs choose 2)
- Design a markov chain where we only care about the set of transactions and
  not the order
- TODO:
  - Read MH part of Gionis and how they figure out d(G) and 10.4 of textbook

## 10-14-21: Meeting

- Constant is sum of degrees
- pi(G) = d(G) / sum of degrees
- pi(G') = d(G') / sum of degrees

## 10-27-21: Meeting

- Write prelims section
  - similar to cube sampling and statpatseq
- Write proofs, definitions, algorithm, etc
- Use macros
- Think about whether things can be simplified
- Don't feel bounded by the notation Gionis et al. use
- R for the rows and C for the columns
- Make the reader do less work
- Expand on the proofs in Gionis
- And then, implement this
- Thinking about reusing library in the fpsomething?
- Strasten matrix multiplication: search this
- linear algebra library?
- be able to specify number of swaps
- specify number of samples

## 11-03-21: Meeting

- Paper
  - Gionis identify dataset as 0-1 matrices
  - want to emphasize that datasets are not 0-1 matrices, they are instead
    multisets of transactions
  - Matrix is a representation of a dataset, so there are actually multiple
    representations of the same dataset (up to the ordering of the transactions
    of the same length)
  - Distinguish a dataset from its representation
  - Decoupling the concept of a dataset from the concept of a matrix
  - Ignoring the differences distorts the null space (over weights same
    datasets)
- Implementation
  - Gionis method
  - Both our methods
  - Sample from these chains by saying
    - Take this many steps
  - Need to measure how many steps we need
    - Figure out what Gionis is doing
  - We want to compare the set of frequent itemsets we found vs Gionis et al
    (or p-value)
  - Maybe use java, take a look and Stefan's work
  - Probably need to operate in log space
- Next steps
  - Put all stuff in paper then move to the implementation

## 11-10-21: Meeting

- Create a matrix wrapper
- Have sum of rows and columns as part of the object...maybe list of edges to
  sample from as well?
- Create these data structures when initializing the matrix
- If we have properties of a matrix object, they should be in the same class
- Add more comments

## 12-01-21: Meeting

- Questions
  - Creating separate transformer classes which create the matrix, since each
    algorithm needs different data structures
  - Create separate matrix classes for each algorithm which subclass the Matrix
    class, since each algorithm uses different data structures
  - Plan for winter break?
- Work in January
  - Start 10th of January

## 12-08-21: Meeting

- Try to make swap if the difference in length of the transactions is 1
- Think more about having multiple swaps at once

## 12-15-21: Meeting

- Experiments
  - How long does a step take?
  - Measure the initialization step too?
  - How long does it take for the methods to converge to a stationary
    distribution?
    - Take a look at the Gionis paper to see how they do it
    - Talk to Stefan
  - Code to draw samples and mine the itemsets from the samples
- KDD deadline: Feb 10

## 01-14-22: Meeting

- Things to talk about
  - Which datasets to use?
    - [spmf datasets](https://www.philippe-fournier-viger.com/spmf/index.php?link=datasets.php)
  - What the experiments are doing
  - What configurations to use (numReps, minFreq, etc.)?
  - We never actually use the driver in our experiments, should we use it?
  - How should the figures look?
    - Show current figure
  - Machine IP for experiments? Specs?
  - Gionis et al. only used a machine with 2GB of RAM =O
- Don't actually compute rowProdMatrix, just compute dot product when we need it
- Make driver take the path
- Make own sparse matrix: array of hash maps (colIndex -> value)
- Meeting at 1 (later... maybe 1.30 or 2) next Tuesday
- Send ssh key

## 01-19-22: Meeting

- Things to talk about
  - Table V in GMMT: if F is the number of frequent itemsets and F_s is the
  number of significant itemsets, then |F \cap F_s| / |F| = |F_s| / |F| and |F \
  F_s| / |F| = (|F| - |F_s|) / |F|, correct? This is because F_s \subseteq F.
  - Should we run multiple reps for an experiment using a different seed each
  time?
    - See one run for now on a single dataset and then decide what we want
    multiple runs of
    - Diffusr probably just one run (if there is time run 5)
  - Thoughts on measuring setup time for samplers? We don't log it right now
  because it was easier to write the code that way, but adding it shouldn't be
  difficult if we want it.
    - Put some code around it
  - Experiment configurations? How many total swaps to take for measuring step
  times, number of estimate samples, number of WY samples, etc.
    - T: 10048 (32 procs), maybe start with a little less like 2048 (that is a
    multiple of 32)
    - P: 100
    - 10,000 steps first for runtimes
    - convergence: 0.1m, 0.5, 0.75m (something like this), 2m 3m, ..., 10m (see
    how long they take first, do something that can run overnight 12h)
  - Are the datasets we have right now fine (chess, mushrooms, bms1, bms2)? They
  tend to be on the smaller side since larger ones would probably take a really
  long time (should we be concerned about this though?).
    - Take ibm generator take the same parameters, as we increase the number of
    - Use accidents if we have time
    transactions in the dataset, how does the sampling time take
      - Idea for the future: take dataset, and duplicate transactions, etc
      - Another idea for the future: generate random datasets and see if our
      algorithms classify any frequent itemsets as significant...they shouldn't
  - Should we log times in ms or something less granular to prevent overflow
    - check, but it should be fine..even if it overflows, it should be fine
  - Think about writing the experimental section

## 01-25-22: Meeting

- Remove code for relative number of frequent itemsets (since it is wrong)
- Raise RAM to maybe 94 or 96 something
- Keep Matteo posted on how the runtime and convergence experiments go for BMS
- Get rid of rowPairToNumEntriesNeq map
  - Now we can add statement of if numEntriesNeq > 4, then continue

## 01-28-22: Meeting

- Diffusr experiment (chess will take 10 days at least if we use
  numEstSamples=10048)
  - Use 2048 instead
- todos in experiment section
- save images to pdf so it is in higher resolution
- Fit whole name (average relative support difference), number of swaps
  multiplier for k or swap number multiplier in axis, also include mathematical
  definition of k in caption
- try to fit stats for w into dataset statistics. Don't use avg. |t|, and remove
  100% for density and just use decimals
- use different styles for lines (be consistent) no need for markers of where
  the points actually. See how the markers look though (but it might be too busy)
- redo algorithm orders for tables and figures (naive, refined, GMMT)
- For step time statistics have (\cmidrule) and step time (ms) above
- Prepare command line diffusr experiment for matteo to run on another machine
- Create datasets with something like mushrooms (5,000 10,000 15,000 20,000
  transactions) and then run 10,000 swaps on each

## 02-01-22: Meeting

- Paper
  - 947: should we say something about how the minimum step time for foodmart is
    not actually 0?
    - Write less than 1 here
  - How come sometimes we use D and D' and other times we use D' and D''
  - Why is theorem 5.5 before our definition of dts on 709?
    - Leave todo for matteo here
  - Equation of ARSD, circ above dataset under fraction doesn't display well
  - How to cite ibm generator?
    - Put cite missing here...there is a paper somewhere
  - How to explain increase variance in scalability?
- TODO
  - check JACCARD(A, B) = |A \cap B| / |A \cup B|
  - A \subseteq B? B \subseteq A?
    - i.e., check that GMMT is a subset of Diffusr-N, for Diffusr-R, all
      combinations of sets (should be 3 combinations)
  - Try greyscale for figures, make sure they work. For boxplot, try to find
    different styles
  - Try to make legend for boxplot such that the names are in order from left to
    right, similar to the plot
  - Use scale property of includegraphics to shrink figures more. It should take
    2/3rds of what it is taking right now (boxplot). Make sure text is legible,
    if not, make text bigger, while keeping figure small
  - boxplot put horizontal lines for y-axis
  - Explain todo: box increases because step times increase, if you multiply
    everything by 4, IQR increases
  - Add todo for matteo to fix circle above D in ARSD measure
  - Use figure* for convergence figures so that they span 2 columns
  - Have figure with 4 subfigures
    - 1 is boxplot
    - 3 is convergence (make sure chess is here, BMS1, and then put 1 that has
      k=1)
    - Write results for other datasets are similar and they are in the appendix
    - If 4 doesn't fit, do 3 (1 and 2)

## 02-02-22: Meeting

- Questions about paper
  - Theorem 4.1 why do we use datasets as inputs instead of matrices?
  - 766: mts use matrix instead of dataset?
- TODO:
  - Figures
    - Use white background instead of gray,and use some gray line for axis grid
    - Make legend larger for scalability by increasing y-axis scale, so the
      legend doesn't overlap with the whiskers
    - Try just having horizontal axis for convergence figures
    - Try making the lines thicker, or may less thicker to make convergence
      figure more legible?
  - Kill Refined mushrooms and run GMMT for chess
  - Run foodmart with higher threshold (don't mine samples again)
    - Maybe pick 2 or 3 thresholds

## 02-08-22: Meeting

- TODO
  - Run analysis on Naive and what we have for GMMT
    - Copy last 128 est samples to a new directory and rename them to wy, then
      run analysis on the est samples, minus those 128, and those 128 wy samples
    - We can delete foodmart1,2,3, to get more disk space
    - Copy results from GMMT to other machine since it has more space. Only need
      to copy the itemsets, not the matrices

## 02-24-22: Meeting

- Need to start writing thesis
  - Take paper and add some stuff
  - Use template on GitHub
  - See how long it is
  - Add examples in prelims
  - Maybe re-add stuff for significant patterns
  - Maybe add more for limitations and future work
  - Matteo doesn't expect that we need to change much
  - Cap is 40 pages, infinite appendix

## 03-03-22: Meeting

- Use bibtex instead of biblio.tex
- Merge introduction and related work into one chapter
- Merge chapters 4 and 5
- Try to move everything from the appendix into the main text and then see how
  it looks. Then, we decide what to move back to the appendix
- Read thesis and see what we need to add/expand and what could easily go into
  the appendix
- Have a prioritized list of what can go into the appendix
- Send message to Matteo about when changes have been made

## 03-10-22: Meeting

- Items to mentions
  - [Thesis website](https://www.amherst.edu/academiclife/departments/computer_science/major/honors)
    - "The body of the honors thesis, excluding the cover page, dedication,
      table of contents, bibliography, and appendices, must not exceed fifty
      pages. No exceptions to this maximum page limit will be accepted."
  - The body of the thesis is currently ~37 pages, so we have a fair bit of
    space for now
  - Things to add
    - Examples
      1. Transactional dataset: calculating support and set of frequent itemsets
      1. Null model: show other datasets that belong to the same null model
      1. Markov chains for the 3 algorithms:
         for each chain, show all states, the transition probabilities, and the
         stationary distribution (maybe...might be a lot of work)
        - tkz graph package (in french)
    - Add back multiple hypothesis testing with WY? (start with the examples
      first)
  - Things to possibly put in the appendix
    1. Proofs
    1. Pseudocode
    1. Figures/tables
    1. Examples
  - Things to remove
    - Mentions of "the extended version"
- Can create a paragraph called "Future Work" where we can put stuff that
  references "extended version"

## 03-32-22: Meeting

- Feedback from presentation?
  - If we have to give a talk again: revise so that we have clear punchlines
    about what was and wasn't available before, and what we have now
  - Example: the answer to Lee's question should somehow be integrated in the
    talk
- Feedback for examples
  - For instances where there is "something going on / similarities between
    matrices etc" mention it!
- Feedback for paragraph responding to Lee's question
  - Is distortion always undesirable? <- start paragraph with this
  - If ..., then there is no distortion in this case, so the question is moot.
  - Remove that is
  - Replace null space with null set Y
  - Replace injective map with bijective function
- Other thesis feedback:
  - Replace extended version with interesting direction future work (remember for
    defense)
  - Put link of actual repo instead of anonymous link
    - Write: for access, write to professor riondato

## 04-05-22: Meeting

- Points to clarify?
  - "A null model, is in some sense, independent from the task whose results one
    wants to validate..." (page 4)
    - What is the null model independent from? The task or result?
      - Answer: task can be thought as the algorithm you are executing. E.g.,
        finding the set of frequent itemsets
  - "...were introduced with the goal of the pattern explosions due to
    frequencies,..." (page 5)
    - What is "the goal of the pattern explosions due to frequencies"?
      - TODO: fix
  - "Additionally, these classes contain many patterns that would never
    be marked as significant (e.g., because they do not appear in the observed
    dataset)..." (page 6)
    - How do these classes contain patterns that don't appear in the observed
      dataset? Isn't the class the set of hypothesis we want to test?
      - Answer: for the Bonferroni correction method, we need to know the number
        of hypotheses we want to test a priori; some of theses hypotheses
        wouldn't be in the observed dataset
  - "...the iterative setting" (page 7)
    - What is the iterative setting?
      - Answer: iterative setting has two meanings. (1) after looking at one
        hypothesis, we look at another hypothesis, so these hypotheses are
        dependent. (2) the dataset grows or changes after every test
  - Notation for empirical p-value
    - Why is it a function of \dataset, shouldn't it be \odataset?
      - TODO: fix
  - "...one must first specify an initial neighborhood structure for P,..."
    (page 13)
    - Why initial? Can't we just say specify a neighborhood structure? Using
      initial might lead the reader to think that there are other neighborhood
      structures after the initial one. We use "initial neighborhood structure"
      in other places too.
      - Initial neighborhood as in before MH, each state may not have self-loops
  - For theorem 3.1 should we use set brackets around item i in the item
    support?
    - TODO: fix
  - "Define the surjective function...of the SLISP null models for \odataset..."
    (page 18)
    - Is "models" supposed to be plural?
      - TODO: fix
- TODO
  - Make changes to paper and thesis
    - Fix notation of empirical p-value
    - Put set bracket around item?
    - Make models singular
